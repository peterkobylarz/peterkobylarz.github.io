{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9daaf9-20db-4ea6-ac71-a64de85111c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "import earthpy as et\n",
    "import earthpy.earthexplorer as etee\n",
    "import earthpy.spatial as es\n",
    "import geopandas as gpd\n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import rioxarray as rxr\n",
    "import rioxarray.merge as rxrm\n",
    "\n",
    "data_dir = os.path.join(et.io.HOME, et.io.DATA_NAME)\n",
    "chi_dir = os.path.join(data_dir, 'chicago-neighborhoods')\n",
    "ndvi_dir = os.path.join(data_dir, 'chicago-green-space', 'processed')\n",
    "\n",
    "for a_dir in [data_dir, chi_dir, ndvi_dir]:\n",
    "    if not os.path.exists(a_dir):\n",
    "        os.makedirs(a_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e479f370-7c00-4101-8e22-79398ee4953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download neighborhoods shapefile and create GDF of Humboldt Park\n",
    "chi_path = os.path.join(chi_dir, 'chicago-neighborhoods.shp')\n",
    "if not os.path.exists(chi_path):\n",
    "    chi_url = ('https://data.cityofchicago.org/api/geospatial/bbvz-uum9?'\n",
    "               'method=export&format=Shapefile')\n",
    "    gpd.read_file(chi_url).to_file(chi_path)\n",
    "\n",
    "chi_gdf = gpd.read_file(chi_path).set_index('pri_neigh')\n",
    "neigh_gdf = (\n",
    "    chi_gdf.\n",
    "    loc[['Humboldt Park', 'Lincoln Park']]\n",
    ")\n",
    "neigh_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad04ea80-54a9-4031-b64d-75c05dbe5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_neighborhood_data(name, geometry, start, end):\n",
    "    \"\"\"\n",
    "    Download NAIP raster for a given geometry, start date, and end date\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    name : str\n",
    "      The name used to label the download\n",
    "    geometry : shapely.POLYGON\n",
    "      The geometry to derive the download extent from. \n",
    "      Must have a `.bounds` attribute.\n",
    "    start : str\n",
    "      The start date as 'YYYY-MM-DD'\n",
    "    end : strL\n",
    "      The end date as 'YYYY-MM-DD'\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    downloader : earthpy.earthexplorer.EarthExplorerDownloader\n",
    "      Object with information about the download, including the data directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'Downloading NAIP for {name}')\n",
    "    bbox = etee.BBox(*geometry.bounds)\n",
    "    #label = row.pri_neigh.lower().replace(' ', '-')\n",
    "    naip_downloader = etee.EarthExplorerDownloader(\n",
    "        dataset=\"NAIP\", \n",
    "        label=name.lower().replace(' ', '-'), \n",
    "        bbox=bbox,\n",
    "        start=start, \n",
    "        end=end,\n",
    "        store_credential=True)\n",
    "    #print(naip_downloader.label)\n",
    "    #print(naip_downloader.bbox.urx, naip_downloader.bbox.ury)\n",
    "    naip_downloader.submit_download_request()\n",
    "    naip_downloader.download(override=False)\n",
    "    return naip_downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f079aafc-04d9-4948-9fb3-7a22b8c08650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_merge_arrays(name):\n",
    "    \"\"\"\n",
    "    Load in and merge downloaded arrays\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    name : str\n",
    "      The name used to label the download\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    merge_da : rxr. DataArray\n",
    "        DataArray with the merged data\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'Merging array for {name}')\n",
    "    data_path = os.path.join(\n",
    "        et.io.HOME, et.io.DATA_NAME,\n",
    "        name.lower().replace(' ', '-'))\n",
    "    tif_paths = glob(os.path.join(data_path, '*.tif'))\n",
    "    das = [rxr.open_rasterio(tp, masked=True) for tp in tif_paths]\n",
    "    merged_da = rxrm.merge_arrays(das)\n",
    "    return merged_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500eea99-0b70-49b1-9c6c-160da9da8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndvi_statistics(gdf, da, stats_path, override=False):\n",
    "    \"\"\"\n",
    "    Calculate NDVI, then summarize and save statistics\n",
    "    \n",
    "    Uses downloaded National Agricultural Imagery Program (NAIP)\n",
    "    data.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    gdf : gpd.GeoDataFrame\n",
    "      A geodataframe with a single row/neighborhood name/boundary\n",
    "    da : rxr.DataArray\n",
    "      Multispectral (NAIP) raster data\n",
    "    stats_path : pathlike\n",
    "      Path to the statistics CSV file\n",
    "    \"\"\"\n",
    "    name = str(gdf.index[0])\n",
    "    print(f'Calculate NDVI and statistics for {name}')\n",
    "    # Caching for existing data\n",
    "    file_is_empty = True\n",
    "    if os.path.exists(stats_path):\n",
    "        print('Stats file exists.')\n",
    "        stats_df = pd.read_csv(stats_path)\n",
    "        file_is_empty = len(stats_df)==0\n",
    "        print(f'Stats file is empty? {file_is_empty}')\n",
    "        \n",
    "        if not file_is_empty:\n",
    "            if (name in list(stats_df.neighborhood)) and (not override):\n",
    "                print(f'Stats exist for {name}, skipping')\n",
    "                return            \n",
    "            \n",
    "    reprojected_gdf = gdf.to_crs(da.rio.crs)\n",
    "    # clip the NAIP tile to the bounds of the neighborhood gdf\n",
    "    naip_crop_da = da.rio.clip_box(*reprojected_gdf.total_bounds)\n",
    "\n",
    "    # Clip to extent of neighborhood\n",
    "    naip_da = naip_crop_da.rio.clip(reprojected_gdf.geometry)\n",
    "\n",
    "    # Calculate NDVI\n",
    "    ndvi_da = (\n",
    "        (naip_da.sel(band=4) - naip_da.sel(band=1))\n",
    "        / (naip_da.sel(band=4) + naip_da.sel(band=1))\n",
    "    )\n",
    "\n",
    "    #Calculate NDVI stats for neighborhood and append to CSV\n",
    "    print(f'Writing stats for {name}')\n",
    "    mode = 'w' if file_is_empty else 'a'\n",
    "    pd.DataFrame(dict(\n",
    "        neighborhood=[name],\n",
    "        ndvi_minimum=[float(ndvi_da.min())],\n",
    "        ndvi_maximum=[float(ndvi_da.max())],\n",
    "        ndvi_median=[float(ndvi_da.median())],\n",
    "        ndvi_25pctl=[np.nanpercentile(ndvi_da.values, 25)],\n",
    "        ndvi_75pctl=[np.nanpercentile(ndvi_da.values, 75)],\n",
    "        ndvi_mean=[float(ndvi_da.mean())],\n",
    "        ndvi_stddev=[float(ndvi_da.std())]\n",
    "        )).to_csv(stats_path, mode='a', header=file_is_empty, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f12fed-d35f-4f86-a619-dea7df786acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_stats_path = os.path.join(ndvi_dir, 'neighborhood-ndvi-stats.csv')\n",
    "\n",
    "for neighborhood_name, details in chi_gdf.iterrows():\n",
    "    if not os.path.exists(ndvi_stats_path):\n",
    "        print('NDVI stats file does not exist...')\n",
    "        ndvi_stats_df = pd.DataFrame()\n",
    "    else:\n",
    "        ndvi_stats_df = pd.read_csv(ndvi_stats_path, index_col=\"neighborhood\")\n",
    "    if neighborhood_name in ndvi_stats_df.index:\n",
    "        print(f'Neighborhood stats for {neighborhood_name} have already been calculated. Skipping')\n",
    "        continue\n",
    "        \n",
    "    downloader = download_neighborhood_data(\n",
    "        neighborhood_name, details.geometry, '2021-01-01', '2021-12-31')\n",
    "    merged_da = load_and_merge_arrays(neighborhood_name)\n",
    "    calculate_ndvi_statistics(chi_gdf.loc[[neighborhood_name]], merged_da, ndvi_stats_path)\n",
    "    del merged_da\n",
    "    \n",
    "    # shutil.rmtree(downloader.data_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
